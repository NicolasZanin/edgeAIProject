{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project EdgeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, shutil\n",
    "\n",
    "listQuery = [\"Emberiza citrinella\", \"Alauda arvensis\", \"Cuculus canorus\" ] #, \"Emberiza cirlus\", \"Tyto alba\", \"Falco tinnunculus\", \"Sylvia borin\", \"Muscicapa striata\", \"Tachybaptus ruficollis\", \"Delichon urbicum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://xeno-canto.org/api/2/recordings?query=\"\n",
    "\n",
    "def enregistrer_mp3(url_api, nom_fichier):\n",
    "    reponse = requests.get(url_api, stream=True)\n",
    "    \n",
    "    if reponse.status_code == 200:\n",
    "        with open(nom_fichier, 'wb') as fichier_audio:\n",
    "            reponse.raw.decode_content = True\n",
    "            shutil.copyfileobj(reponse.raw, fichier_audio)\n",
    "        print(\"Audio enregistré avec succès sous le nom :\", nom_fichier)\n",
    "    else:\n",
    "        print(\"Erreur lors de la récupération des données audio depuis l'API\")\n",
    "\n",
    "def getData(query):\n",
    "    url_api = url + query\n",
    "    response = requests.get(url_api)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        contenu = response.json()[\"recordings\"]\n",
    "        pathToDir = \"./data/\" + query\n",
    "\n",
    "        if not os.path.exists(pathToDir):\n",
    "            os.mkdir(pathToDir)\n",
    "\n",
    "            for _, element in zip(range(250), contenu):\n",
    "                elementUrl = element[\"file\"]\n",
    "                elementFileName = element[\"file-name\"]\n",
    "                storeFile = pathToDir + \"/\" + elementFileName\n",
    "                \n",
    "                if not os.path.exists(storeFile):\n",
    "                    try:\n",
    "                        enregistrer_mp3(elementUrl, storeFile)\n",
    "                    except: # Pour les problèmes de noms de fichiers\n",
    "                        pass\n",
    "\n",
    "for query in listQuery:\n",
    "    getData(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.activations import softmax\n",
    "\n",
    "from keras.layers import Input, Conv1D, MaxPool1D, Flatten, Dense, AvgPool1D, Activation\n",
    "from keras.utils import get_file\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "dataset_dir = Path('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all sound in X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "def slice_audio_with_trim(file_path, index, duration=1):\n",
    "    audio_data, sampling_rate = librosa.load(file_path, sr=None)\n",
    "    non_silent_audio, _ = librosa.effects.trim(audio_data)\n",
    "    num_slices = int(len(non_silent_audio) / sampling_rate / duration)\n",
    "\n",
    "    # Diviser l'audio en fonction de duration\n",
    "    for i in range(num_slices):\n",
    "        start = i * sampling_rate * duration\n",
    "        end = start + sampling_rate * duration\n",
    "        slice_data = non_silent_audio[start:end]\n",
    "\n",
    "        data = slice_data.astype(np.float32)\n",
    "        data.resize((16000, 1))\n",
    "\n",
    "        x.append(data)\n",
    "        y.append(index)\n",
    "\n",
    "def getAllDataClasses(directory, index):\n",
    "    for recording in dataset_dir.glob(f'{directory}/*'):\n",
    "        slice_audio_with_trim(str(recording) ,index)\n",
    "\n",
    "def loadAllData():\n",
    "    for i in range(len(listQuery)):\n",
    "        getAllDataClasses(listQuery[i], i)\n",
    "\n",
    "loadAllData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[   0 1121 2242]\n",
      "[1121 1121 1121]\n"
     ]
    }
   ],
   "source": [
    "u, indexes, counts = np.unique(y, return_index=True, return_counts=True)\n",
    "min = np.min(counts)\n",
    "nbrClasses = len(u)\n",
    "\n",
    "indices = np.random.permutation(min)\n",
    "\n",
    "newX = []\n",
    "newY = []\n",
    "\n",
    "for i in range(nbrClasses):\n",
    "    sousSetX = []\n",
    "    sousSetY = []\n",
    "    \n",
    "    if i == nbrClasses - 1:\n",
    "        sousSetX = x[indexes[i]:]\n",
    "        sousSetY = y[indexes[i]:]\n",
    "    else:\n",
    "        sousSetX = x[indexes[i] : indexes[i + 1]]\n",
    "        sousSetY = y[indexes[i] : indexes[i + 1]]\n",
    "    \n",
    "    x_selectionne = [sousSetX[j] for j in indices]\n",
    "    y_selectionne = [sousSetY[j] for j in indices]\n",
    "\n",
    "    for x_s, y_s in zip(x_selectionne, y_selectionne):\n",
    "        newX.append(x_s)\n",
    "        newY.append(y_s)\n",
    "\n",
    "u, indexes, counts = np.unique(newY, return_index=True, return_counts=True)\n",
    "print(u)\n",
    "print(indexes)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(newX, newY, test_size=0.2)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "y_test = to_categorical(np.array(y_test))\n",
    "\n",
    "perms = np.random.permutation(len(y_test))[0:250]\n",
    "\n",
    "x_test_250 = x_test[perms]\n",
    "y_test_250 = y_test[perms]\n",
    "\n",
    "np.savetxt('x_test_gsc_250.csv', x_test_250.reshape((x_test_250.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test_gsc_250.csv', y_test_250, delimiter=',', fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2690, 16000, 1) (673, 16000, 1)\n",
      "(2690, 3) (673, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " max_pooling1d_58 (MaxPoolin  (None, 1333, 1)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_48 (Conv1D)          (None, 1331, 16)          64        \n",
      "                                                                 \n",
      " max_pooling1d_59 (MaxPoolin  (None, 332, 16)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_49 (Conv1D)          (None, 330, 30)           1470      \n",
      "                                                                 \n",
      " max_pooling1d_60 (MaxPoolin  (None, 82, 30)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_12 (Avera  (None, 41, 30)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_50 (Conv1D)          (None, 39, 4)             364       \n",
      "                                                                 \n",
      " max_pooling1d_61 (MaxPoolin  (None, 4, 4)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 2, 32)             416       \n",
      "                                                                 \n",
      " max_pooling1d_62 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,413\n",
      "Trainable params: 2,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "model.add(MaxPool1D(pool_size=12))\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4))\n",
    "model.add(Conv1D(filters=30, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4))\n",
    "model.add(AvgPool1D())\n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=8))\n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=3))\n",
    "model.add(Activation('softmax')) # SoftMax activation needs to be separate from Dense to remove it later on\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-4)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 4s 181ms/step - loss: 1.0982 - categorical_accuracy: 0.3673 - val_loss: 1.0975 - val_categorical_accuracy: 0.3105\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 1.0957 - categorical_accuracy: 0.3390 - val_loss: 1.0952 - val_categorical_accuracy: 0.3120\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 1.0913 - categorical_accuracy: 0.3491 - val_loss: 1.0908 - val_categorical_accuracy: 0.3105\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 1.0834 - categorical_accuracy: 0.3632 - val_loss: 1.0835 - val_categorical_accuracy: 0.3299\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 1.0703 - categorical_accuracy: 0.3717 - val_loss: 1.0721 - val_categorical_accuracy: 0.4012\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 138ms/step - loss: 1.0527 - categorical_accuracy: 0.4372 - val_loss: 1.0609 - val_categorical_accuracy: 0.4205\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 1.0351 - categorical_accuracy: 0.5862 - val_loss: 1.0498 - val_categorical_accuracy: 0.6211\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 1.0178 - categorical_accuracy: 0.6528 - val_loss: 1.0308 - val_categorical_accuracy: 0.6582\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 1.0018 - categorical_accuracy: 0.6294 - val_loss: 1.0160 - val_categorical_accuracy: 0.6449\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.9788 - categorical_accuracy: 0.6732 - val_loss: 0.9924 - val_categorical_accuracy: 0.6642\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 129ms/step - loss: 0.9519 - categorical_accuracy: 0.6476 - val_loss: 0.9695 - val_categorical_accuracy: 0.6137\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.9260 - categorical_accuracy: 0.6301 - val_loss: 0.9463 - val_categorical_accuracy: 0.5676\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 2s 152ms/step - loss: 0.9008 - categorical_accuracy: 0.5855 - val_loss: 0.9230 - val_categorical_accuracy: 0.5706\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.8738 - categorical_accuracy: 0.6089 - val_loss: 0.9025 - val_categorical_accuracy: 0.6107\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 0.8531 - categorical_accuracy: 0.6677 - val_loss: 0.8781 - val_categorical_accuracy: 0.5899\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 2s 137ms/step - loss: 0.8365 - categorical_accuracy: 0.6238 - val_loss: 0.8555 - val_categorical_accuracy: 0.6686\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.8047 - categorical_accuracy: 0.7037 - val_loss: 0.8325 - val_categorical_accuracy: 0.6627\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 2s 145ms/step - loss: 0.7816 - categorical_accuracy: 0.7097 - val_loss: 0.8091 - val_categorical_accuracy: 0.6999\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 129ms/step - loss: 0.7640 - categorical_accuracy: 0.7472 - val_loss: 0.7930 - val_categorical_accuracy: 0.7236\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.7502 - categorical_accuracy: 0.7312 - val_loss: 0.7656 - val_categorical_accuracy: 0.7207\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 129ms/step - loss: 0.7226 - categorical_accuracy: 0.7610 - val_loss: 0.7462 - val_categorical_accuracy: 0.7400\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.7034 - categorical_accuracy: 0.7710 - val_loss: 0.7239 - val_categorical_accuracy: 0.7355\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 129ms/step - loss: 0.6844 - categorical_accuracy: 0.7639 - val_loss: 0.6995 - val_categorical_accuracy: 0.7727\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.6672 - categorical_accuracy: 0.7959 - val_loss: 0.6856 - val_categorical_accuracy: 0.7994\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.6492 - categorical_accuracy: 0.7996 - val_loss: 0.6989 - val_categorical_accuracy: 0.7489\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.6556 - categorical_accuracy: 0.7848 - val_loss: 0.6456 - val_categorical_accuracy: 0.7979\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 0.6191 - categorical_accuracy: 0.8078 - val_loss: 0.6348 - val_categorical_accuracy: 0.7920\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 138ms/step - loss: 0.6038 - categorical_accuracy: 0.8097 - val_loss: 0.6300 - val_categorical_accuracy: 0.7935\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.5908 - categorical_accuracy: 0.8119 - val_loss: 0.6029 - val_categorical_accuracy: 0.8053\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 0.5736 - categorical_accuracy: 0.8204 - val_loss: 0.6002 - val_categorical_accuracy: 0.8187\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 2s 142ms/step - loss: 0.5675 - categorical_accuracy: 0.8234 - val_loss: 0.5974 - val_categorical_accuracy: 0.8009\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 2s 144ms/step - loss: 0.5600 - categorical_accuracy: 0.8204 - val_loss: 0.5708 - val_categorical_accuracy: 0.8202\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 127ms/step - loss: 0.5469 - categorical_accuracy: 0.8335 - val_loss: 0.5585 - val_categorical_accuracy: 0.8187\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 131ms/step - loss: 0.5341 - categorical_accuracy: 0.8349 - val_loss: 0.5552 - val_categorical_accuracy: 0.8039\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 2s 144ms/step - loss: 0.5332 - categorical_accuracy: 0.8190 - val_loss: 0.5571 - val_categorical_accuracy: 0.8202\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.5232 - categorical_accuracy: 0.8219 - val_loss: 0.5472 - val_categorical_accuracy: 0.8336\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.5165 - categorical_accuracy: 0.8275 - val_loss: 0.5433 - val_categorical_accuracy: 0.8232\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 138ms/step - loss: 0.5055 - categorical_accuracy: 0.8279 - val_loss: 0.5197 - val_categorical_accuracy: 0.8351\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 0.4936 - categorical_accuracy: 0.8338 - val_loss: 0.5238 - val_categorical_accuracy: 0.8291\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.4917 - categorical_accuracy: 0.8320 - val_loss: 0.5255 - val_categorical_accuracy: 0.8291\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 129ms/step - loss: 0.4887 - categorical_accuracy: 0.8301 - val_loss: 0.5092 - val_categorical_accuracy: 0.8306\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 0.4802 - categorical_accuracy: 0.8375 - val_loss: 0.4947 - val_categorical_accuracy: 0.8306\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.4713 - categorical_accuracy: 0.8413 - val_loss: 0.4926 - val_categorical_accuracy: 0.8321\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.4682 - categorical_accuracy: 0.8431 - val_loss: 0.4890 - val_categorical_accuracy: 0.8380\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 127ms/step - loss: 0.4656 - categorical_accuracy: 0.8435 - val_loss: 0.4892 - val_categorical_accuracy: 0.8351\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.4638 - categorical_accuracy: 0.8364 - val_loss: 0.4912 - val_categorical_accuracy: 0.8410\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.4596 - categorical_accuracy: 0.8457 - val_loss: 0.4899 - val_categorical_accuracy: 0.8217\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 0.5337 - categorical_accuracy: 0.8190 - val_loss: 0.5065 - val_categorical_accuracy: 0.8187\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.4583 - categorical_accuracy: 0.8379 - val_loss: 0.4730 - val_categorical_accuracy: 0.8455\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.4620 - categorical_accuracy: 0.8357 - val_loss: 0.4777 - val_categorical_accuracy: 0.8425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18e66d177c0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=268, validation_data=(x_test, y_test))\n",
    "# model.fit(x_train, y_train, epochs=25, batch_size=268, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s - loss: 0.4777 - categorical_accuracy: 0.8425 - 321ms/epoch - 15ms/step\n",
      "22/22 [==============================] - 0s 11ms/step\n",
      "tf.Tensor(\n",
      "[[174  54   5]\n",
      " [ 16 208   6]\n",
      " [ 20   5 185]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.4748 - categorical_accuracy: 0.8440 - 149ms/epoch - 19ms/step\n",
      "8/8 [==============================] - 0s 11ms/step\n",
      "tf.Tensor(\n",
      "[[67 19  4]\n",
      " [ 4 83  2]\n",
      " [ 9  1 61]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test_250, y_test_250, verbose=2)\n",
    "pred_test_250 = model.predict(x_test_250)\n",
    "print(tf.math.confusion_matrix(y_test_250.argmax(axis=1), pred_test_250.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('project.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('project.h5')\n",
    "if isinstance(model.layers[-1], Activation) and model.layers[-1].activation == softmax:\n",
    "    model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)\n",
    "else:\n",
    "    print('Error: last layer is not SoftMax Activation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qualia_codegen_core in c:\\users\\bobca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bobca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from qualia_codegen_core) (3.1.3)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\bobca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from qualia_codegen_core) (4.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\bobca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from qualia_codegen_core) (1.24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bobca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->qualia_codegen_core) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qualia_codegen_core\n",
    "import qualia_codegen_core\n",
    "from qualia_codegen_core.graph.KerasModelGraph import KerasModelGraph\n",
    "from qualia_codegen_core.graph.Quantization import Quantization\n",
    "from qualia_codegen_core.graph.RoundMode import RoundMode\n",
    "\n",
    "from importlib.resources import files\n",
    "main_path = str((files('qualia_codegen_core.examples')/'Linux'/'main.cpp').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                                           | Layer                                            | Outputs                                          | Input shape                                      | Output shape                                    \n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                                 | input_13                                         | max_pooling1d_58                                 | (1, 16000, 1)                                    | ((1, 16000, 1),)                                \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "input_13                                         | max_pooling1d_58                                 | conv1d_48                                        | (1, 16000, 1)                                    | ((1, 1333, 1),)                                 \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_58                                 | conv1d_48                                        | max_pooling1d_59                                 | (1, 1333, 1)                                     | ((1, 1331, 16),)                                \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_48                                        | max_pooling1d_59                                 | conv1d_49                                        | (1, 1331, 16)                                    | ((1, 332, 16),)                                 \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_59                                 | conv1d_49                                        | max_pooling1d_60                                 | (1, 332, 16)                                     | ((1, 330, 30),)                                 \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_49                                        | max_pooling1d_60                                 | average_pooling1d_12                             | (1, 330, 30)                                     | ((1, 82, 30),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_60                                 | average_pooling1d_12                             | conv1d_50                                        | (1, 82, 30)                                      | ((1, 41, 30),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "average_pooling1d_12                             | conv1d_50                                        | max_pooling1d_61                                 | (1, 41, 30)                                      | ((1, 39, 4),)                                   \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_50                                        | max_pooling1d_61                                 | conv1d_51                                        | (1, 39, 4)                                       | ((1, 4, 4),)                                    \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_61                                 | conv1d_51                                        | max_pooling1d_62                                 | (1, 4, 4)                                        | ((1, 2, 32),)                                   \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_51                                        | max_pooling1d_62                                 | flatten_10                                       | (1, 2, 32)                                       | ((1, 1, 32),)                                   \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_62                                 | flatten_10                                       | dense_10                                         | (1, 1, 32)                                       | ((1, 32),)                                      \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "flatten_10                                       | dense_10                                         |                                                  | (1, 32)                                          | ((1, 3),)                                       \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelgraph = KerasModelGraph(model).convert()\n",
    "print(modelgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\average_pooling1d\n",
      "......vars\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...layers\\max_pooling1d\n",
      "......vars\n",
      "...layers\\max_pooling1d_1\n",
      "......vars\n",
      "...layers\\max_pooling1d_2\n",
      "......vars\n",
      "...layers\\max_pooling1d_3\n",
      "......vars\n",
      "...layers\\max_pooling1d_4\n",
      "......vars\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-28 14:36:15         5312\n",
      "metadata.json                                  2024-04-28 14:36:15           64\n",
      "variables.h5                                   2024-04-28 14:36:15        39232\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-28 14:36:14         5312\n",
      "metadata.json                                  2024-04-28 14:36:14           64\n",
      "variables.h5                                   2024-04-28 14:36:14        39232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graphviz not available\n",
      "Activation function TActivation.SOFTMAX not supported\n",
      "ModelGraph validation failed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m float_res \u001b[38;5;241m=\u001b[39m qualia_codegen_core\u001b[38;5;241m.\u001b[39mConverter(output_path\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_output_floating\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mconvert_model(float_modelgraph)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_model_floating.h\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfloat_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not None"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\average_pooling1d\n",
      "......vars\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...layers\\max_pooling1d\n",
      "......vars\n",
      "...layers\\max_pooling1d_1\n",
      "......vars\n",
      "...layers\\max_pooling1d_2\n",
      "......vars\n",
      "...layers\\max_pooling1d_3\n",
      "......vars\n",
      "...layers\\max_pooling1d_4\n",
      "......vars\n",
      "...vars\n"
     ]
    }
   ],
   "source": [
    "float_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for float32\n",
    "for node in float_modelgraph.nodes:\n",
    "    # No scale factor if not fixed-point quantization on integers\n",
    "    node.q = Quantization(\n",
    "            number_type=float,\n",
    "            width=32,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=0,\n",
    "            output_scale_factor=0,\n",
    "            weights_round_mode=RoundMode.NONE,\n",
    "            output_round_mode=RoundMode.NONE,\n",
    "            )\n",
    "\n",
    "float_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_floating')).convert_model(float_modelgraph)\n",
    "\n",
    "with open('gsc_model_floating.h', 'w') as f:\n",
    "    f.write(float_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cc1plus.exe: fatal error: gsc_output_fixed/model.c: No such file or directory\n",
      "compilation terminated.\n",
      "<command-line>: fatal error: gsc_output_fixed/include/defines.h: No such file or directory\n",
      "compilation terminated.\n"
     ]
    }
   ],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_fixed -include gsc_output_fixed/include/defines.h -Igsc_output_fixed/include gsc_output_fixed/model.c {main_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\average_pooling1d\n",
      "......vars\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...layers\\max_pooling1d\n",
      "......vars\n",
      "...layers\\max_pooling1d_1\n",
      "......vars\n",
      "...layers\\max_pooling1d_2\n",
      "......vars\n",
      "...layers\\max_pooling1d_3\n",
      "......vars\n",
      "...layers\\max_pooling1d_4\n",
      "......vars\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-28 14:36:20         5312\n",
      "metadata.json                                  2024-04-28 14:36:20           64\n",
      "variables.h5                                   2024-04-28 14:36:20        39232\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-28 14:36:20         5312\n",
      "metadata.json                                  2024-04-28 14:36:20           64\n",
      "variables.h5                                   2024-04-28 14:36:20        39232\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\average_pooling1d\n",
      "......vars\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...layers\\max_pooling1d\n",
      "......vars\n",
      "...layers\\max_pooling1d_1\n",
      "......vars\n",
      "...layers\\max_pooling1d_2\n",
      "......vars\n",
      "...layers\\max_pooling1d_3\n",
      "......vars\n",
      "...layers\\max_pooling1d_4\n",
      "......vars\n",
      "...vars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graphviz not available\n"
     ]
    }
   ],
   "source": [
    "fixed_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for int16 Q9.7\n",
    "for node in fixed_modelgraph.nodes:\n",
    "    node.q = Quantization(\n",
    "            number_type=int,\n",
    "            width=16,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=7,\n",
    "            output_scale_factor=7,\n",
    "            weights_round_mode=RoundMode.FLOOR,\n",
    "            output_round_mode=RoundMode.FLOOR,\n",
    "            )\n",
    "\n",
    "fixed_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_fixed')).convert_model(fixed_modelgraph)\n",
    "\n",
    "with open('gsc_model_fixed.h', 'w') as f:\n",
    "    f.write(fixed_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'.' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_fixed -include gsc_output_fixed/include/defines.h -Igsc_output_fixed/include gsc_output_fixed/model.c {main_path}\n",
    "!./gsc_fixed x_test_gsc_250.csv y_test_gsc_250.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
