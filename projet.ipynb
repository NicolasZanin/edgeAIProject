{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project EdgeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, shutil\n",
    "\n",
    "listQuery = [\"Emberiza citrinella\", \"Alauda arvensis\", \"Emberiza cirlus\", \"Cuculus canorus\"] #, \"Tyto alba\", \"Falco tinnunculus\", \"Sylvia borin\", \"Muscicapa striata\", \"Tachybaptus ruficollis\", \"Delichon urbicum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://xeno-canto.org/api/2/recordings?query=\"\n",
    "\n",
    "def enregistrer_mp3(url_api, nom_fichier):\n",
    "    reponse = requests.get(url_api, stream=True)\n",
    "    \n",
    "    if reponse.status_code == 200:\n",
    "        with open(nom_fichier, 'wb') as fichier_audio:\n",
    "            reponse.raw.decode_content = True\n",
    "            shutil.copyfileobj(reponse.raw, fichier_audio)\n",
    "        print(\"Audio enregistré avec succès sous le nom :\", nom_fichier)\n",
    "    else:\n",
    "        print(\"Erreur lors de la récupération des données audio depuis l'API\")\n",
    "\n",
    "def getData(query):\n",
    "    url_api = url + query\n",
    "    response = requests.get(url_api)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        contenu = response.json()[\"recordings\"]\n",
    "        pathToDir = \"./data/\" + query\n",
    "\n",
    "        if not os.path.exists(pathToDir):\n",
    "            os.mkdir(pathToDir)\n",
    "\n",
    "            for _, element in zip(range(250), contenu):\n",
    "                elementUrl = element[\"file\"]\n",
    "                elementFileName = element[\"file-name\"]\n",
    "                storeFile = pathToDir + \"/\" + elementFileName\n",
    "                \n",
    "                if not os.path.exists(storeFile):\n",
    "                    try:\n",
    "                        enregistrer_mp3(elementUrl, storeFile)\n",
    "                    except: # Pour les problèmes de noms de fichiers\n",
    "                        pass\n",
    "\n",
    "for query in listQuery:\n",
    "    getData(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import copy\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.activations import softmax\n",
    "\n",
    "from keras.layers import Input, Conv1D, MaxPool1D, Flatten, Dense, AvgPool1D, Activation\n",
    "from keras.utils import get_file\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "dataset_dir = Path('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all sound in X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "def slice_audio_with_trim(file_path, index, duration=1):\n",
    "    audio_data, sampling_rate = librosa.load(file_path, sr=None)\n",
    "    non_silent_audio, _ = librosa.effects.trim(audio_data)\n",
    "    num_slices = int(len(non_silent_audio) / sampling_rate / duration)\n",
    "\n",
    "    # Diviser l'audio en fonction de duration\n",
    "    for i in range(num_slices):\n",
    "        start = i * sampling_rate * duration\n",
    "        end = start + sampling_rate * duration\n",
    "        slice_data = non_silent_audio[start:end]\n",
    "\n",
    "        data = slice_data.astype(np.float32)\n",
    "        data.resize((16000, 1))\n",
    "\n",
    "        x.append(data)\n",
    "        y.append(index)\n",
    "\n",
    "def getAllDataClasses(directory, index):\n",
    "    for recording in dataset_dir.glob(f'{directory}/*'):\n",
    "        slice_audio_with_trim(str(recording) ,index)\n",
    "\n",
    "def loadAllData():\n",
    "    for i in range(len(listQuery)):\n",
    "        getAllDataClasses(listQuery[i], i)\n",
    "\n",
    "loadAllData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[    0 12744 25488 38232]\n",
      "[12744 12744 12744 12744]\n"
     ]
    }
   ],
   "source": [
    "u, indexes, counts = np.unique(y, return_index=True, return_counts=True)\n",
    "min = np.min(counts)\n",
    "nbrClasses = len(u)\n",
    "\n",
    "indices = np.random.permutation(min)\n",
    "\n",
    "newX = []\n",
    "newY = []\n",
    "\n",
    "for i in range(nbrClasses):\n",
    "    sousSetX = []\n",
    "    sousSetY = []\n",
    "    \n",
    "    if i == nbrClasses - 1:\n",
    "        sousSetX = x[indexes[i]:]\n",
    "        sousSetY = y[indexes[i]:]\n",
    "    else:\n",
    "        sousSetX = x[indexes[i] : indexes[i + 1]]\n",
    "        sousSetY = y[indexes[i] : indexes[i + 1]]\n",
    "    \n",
    "    x_selectionne = [sousSetX[j] for j in indices]\n",
    "    y_selectionne = [sousSetY[j] for j in indices]\n",
    "\n",
    "    for x_s, y_s in zip(x_selectionne, y_selectionne):\n",
    "        newX.append(x_s)\n",
    "        newY.append(y_s)\n",
    "\n",
    "u, indexes, counts = np.unique(newY, return_index=True, return_counts=True)\n",
    "print(u)\n",
    "print(indexes)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(newX, newY, test_size=0.2)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "y_test = to_categorical(np.array(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40780, 16000, 1) (10196, 16000, 1)\n",
      "(40780, 4) (10196, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 15998, 4)          16        \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 1999, 4)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 1997, 4)           52        \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 998, 4)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3992)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 15972     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16040 (62.66 KB)\n",
      "Trainable params: 16040 (62.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=8))\n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4))\n",
    "model.add(Activation('softmax')) # SoftMax activation needs to be separate from Dense to remove it later on\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-4)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "107/107 [==============================] - 28s 257ms/step - loss: 1.2438 - categorical_accuracy: 0.4627 - val_loss: 1.1615 - val_categorical_accuracy: 0.5154\n",
      "Epoch 2/50\n",
      "107/107 [==============================] - 26s 243ms/step - loss: 1.1374 - categorical_accuracy: 0.5111 - val_loss: 1.1222 - val_categorical_accuracy: 0.5278\n",
      "Epoch 3/50\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 1.1077 - categorical_accuracy: 0.5215 - val_loss: 1.0970 - val_categorical_accuracy: 0.5376\n",
      "Epoch 4/50\n",
      "107/107 [==============================] - 26s 241ms/step - loss: 1.0800 - categorical_accuracy: 0.5363 - val_loss: 1.0760 - val_categorical_accuracy: 0.5381\n",
      "Epoch 5/50\n",
      "107/107 [==============================] - 26s 239ms/step - loss: 1.0611 - categorical_accuracy: 0.5456 - val_loss: 1.0598 - val_categorical_accuracy: 0.5389\n",
      "Epoch 6/50\n",
      "107/107 [==============================] - 25s 238ms/step - loss: 1.0487 - categorical_accuracy: 0.5525 - val_loss: 1.0503 - val_categorical_accuracy: 0.5447\n",
      "Epoch 7/50\n",
      "107/107 [==============================] - 26s 240ms/step - loss: 1.0402 - categorical_accuracy: 0.5553 - val_loss: 1.0481 - val_categorical_accuracy: 0.5620\n",
      "Epoch 8/50\n",
      "107/107 [==============================] - 26s 241ms/step - loss: 1.0327 - categorical_accuracy: 0.5592 - val_loss: 1.0396 - val_categorical_accuracy: 0.5686\n",
      "Epoch 9/50\n",
      "107/107 [==============================] - 26s 240ms/step - loss: 1.0231 - categorical_accuracy: 0.5621 - val_loss: 1.0275 - val_categorical_accuracy: 0.5574\n",
      "Epoch 10/50\n",
      "107/107 [==============================] - 26s 242ms/step - loss: 1.0097 - categorical_accuracy: 0.5686 - val_loss: 1.0155 - val_categorical_accuracy: 0.5586\n",
      "Epoch 11/50\n",
      "107/107 [==============================] - 26s 241ms/step - loss: 0.9994 - categorical_accuracy: 0.5711 - val_loss: 1.0082 - val_categorical_accuracy: 0.5686\n",
      "Epoch 12/50\n",
      "107/107 [==============================] - 26s 240ms/step - loss: 0.9911 - categorical_accuracy: 0.5742 - val_loss: 1.0102 - val_categorical_accuracy: 0.5661\n",
      "Epoch 13/50\n",
      "107/107 [==============================] - 26s 242ms/step - loss: 0.9877 - categorical_accuracy: 0.5753 - val_loss: 0.9939 - val_categorical_accuracy: 0.5703\n",
      "Epoch 14/50\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.9815 - categorical_accuracy: 0.5754 - val_loss: 0.9941 - val_categorical_accuracy: 0.5612\n",
      "Epoch 15/50\n",
      "107/107 [==============================] - 26s 242ms/step - loss: 0.9772 - categorical_accuracy: 0.5750 - val_loss: 0.9884 - val_categorical_accuracy: 0.5722\n",
      "Epoch 16/50\n",
      "107/107 [==============================] - 26s 243ms/step - loss: 0.9741 - categorical_accuracy: 0.5774 - val_loss: 1.0010 - val_categorical_accuracy: 0.5680\n",
      "Epoch 17/50\n",
      "107/107 [==============================] - 26s 244ms/step - loss: 0.9687 - categorical_accuracy: 0.5801 - val_loss: 0.9876 - val_categorical_accuracy: 0.5661\n",
      "Epoch 18/50\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.9648 - categorical_accuracy: 0.5813 - val_loss: 0.9831 - val_categorical_accuracy: 0.5741\n",
      "Epoch 19/50\n",
      "107/107 [==============================] - 27s 256ms/step - loss: 0.9619 - categorical_accuracy: 0.5803 - val_loss: 0.9799 - val_categorical_accuracy: 0.5738\n",
      "Epoch 20/50\n",
      "107/107 [==============================] - 28s 264ms/step - loss: 0.9583 - categorical_accuracy: 0.5830 - val_loss: 0.9805 - val_categorical_accuracy: 0.5729\n",
      "Epoch 21/50\n",
      "107/107 [==============================] - 28s 261ms/step - loss: 0.9556 - categorical_accuracy: 0.5846 - val_loss: 0.9781 - val_categorical_accuracy: 0.5730\n",
      "Epoch 22/50\n",
      "107/107 [==============================] - 27s 257ms/step - loss: 0.9529 - categorical_accuracy: 0.5852 - val_loss: 0.9842 - val_categorical_accuracy: 0.5743\n",
      "Epoch 23/50\n",
      "107/107 [==============================] - 27s 248ms/step - loss: 0.9517 - categorical_accuracy: 0.5859 - val_loss: 0.9821 - val_categorical_accuracy: 0.5732\n",
      "Epoch 24/50\n",
      "107/107 [==============================] - 27s 248ms/step - loss: 0.9499 - categorical_accuracy: 0.5842 - val_loss: 0.9764 - val_categorical_accuracy: 0.5737\n",
      "Epoch 25/50\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.9462 - categorical_accuracy: 0.5890 - val_loss: 0.9770 - val_categorical_accuracy: 0.5798\n",
      "Epoch 26/50\n",
      "107/107 [==============================] - 26s 245ms/step - loss: 0.9438 - categorical_accuracy: 0.5871 - val_loss: 0.9767 - val_categorical_accuracy: 0.5726\n",
      "Epoch 27/50\n",
      "107/107 [==============================] - 26s 245ms/step - loss: 0.9431 - categorical_accuracy: 0.5875 - val_loss: 0.9723 - val_categorical_accuracy: 0.5740\n",
      "Epoch 28/50\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 0.9400 - categorical_accuracy: 0.5889 - val_loss: 0.9722 - val_categorical_accuracy: 0.5781\n",
      "Epoch 29/50\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.9366 - categorical_accuracy: 0.5899 - val_loss: 0.9744 - val_categorical_accuracy: 0.5721\n",
      "Epoch 30/50\n",
      "107/107 [==============================] - 26s 245ms/step - loss: 0.9375 - categorical_accuracy: 0.5904 - val_loss: 0.9716 - val_categorical_accuracy: 0.5750\n",
      "Epoch 31/50\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.9307 - categorical_accuracy: 0.5931 - val_loss: 0.9995 - val_categorical_accuracy: 0.5605\n",
      "Epoch 32/50\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.9268 - categorical_accuracy: 0.5948 - val_loss: 0.9678 - val_categorical_accuracy: 0.5809\n",
      "Epoch 33/50\n",
      "107/107 [==============================] - 27s 249ms/step - loss: 0.9247 - categorical_accuracy: 0.5931 - val_loss: 0.9659 - val_categorical_accuracy: 0.5791\n",
      "Epoch 34/50\n",
      "107/107 [==============================] - 27s 252ms/step - loss: 0.9247 - categorical_accuracy: 0.5955 - val_loss: 0.9684 - val_categorical_accuracy: 0.5821\n",
      "Epoch 35/50\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.9189 - categorical_accuracy: 0.5971 - val_loss: 0.9659 - val_categorical_accuracy: 0.5797\n",
      "Epoch 36/50\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 0.9184 - categorical_accuracy: 0.5981 - val_loss: 0.9632 - val_categorical_accuracy: 0.5801\n",
      "Epoch 37/50\n",
      "107/107 [==============================] - 27s 249ms/step - loss: 0.9151 - categorical_accuracy: 0.5984 - val_loss: 0.9647 - val_categorical_accuracy: 0.5791\n",
      "Epoch 38/50\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.9135 - categorical_accuracy: 0.5982 - val_loss: 0.9656 - val_categorical_accuracy: 0.5801\n",
      "Epoch 39/50\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 0.9108 - categorical_accuracy: 0.5992 - val_loss: 0.9622 - val_categorical_accuracy: 0.5791\n",
      "Epoch 40/50\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 0.9108 - categorical_accuracy: 0.5989 - val_loss: 0.9630 - val_categorical_accuracy: 0.5861\n",
      "Epoch 41/50\n",
      "107/107 [==============================] - 26s 245ms/step - loss: 0.9076 - categorical_accuracy: 0.6004 - val_loss: 0.9632 - val_categorical_accuracy: 0.5820\n",
      "Epoch 42/50\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 0.9046 - categorical_accuracy: 0.6029 - val_loss: 0.9657 - val_categorical_accuracy: 0.5850\n",
      "Epoch 43/50\n",
      "107/107 [==============================] - 26s 248ms/step - loss: 0.9052 - categorical_accuracy: 0.6026 - val_loss: 0.9705 - val_categorical_accuracy: 0.5706\n",
      "Epoch 44/50\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.9062 - categorical_accuracy: 0.6007 - val_loss: 0.9628 - val_categorical_accuracy: 0.5838\n",
      "Epoch 45/50\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 0.8998 - categorical_accuracy: 0.6036 - val_loss: 0.9670 - val_categorical_accuracy: 0.5752\n",
      "Epoch 46/50\n",
      "107/107 [==============================] - 27s 249ms/step - loss: 0.8972 - categorical_accuracy: 0.6051 - val_loss: 0.9621 - val_categorical_accuracy: 0.5824\n",
      "Epoch 47/50\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.8981 - categorical_accuracy: 0.6045 - val_loss: 0.9714 - val_categorical_accuracy: 0.5830\n",
      "Epoch 48/50\n",
      "107/107 [==============================] - 26s 248ms/step - loss: 0.8952 - categorical_accuracy: 0.6066 - val_loss: 0.9708 - val_categorical_accuracy: 0.5814\n",
      "Epoch 49/50\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 0.8938 - categorical_accuracy: 0.6075 - val_loss: 0.9643 - val_categorical_accuracy: 0.5825\n",
      "Epoch 50/50\n",
      "107/107 [==============================] - 27s 248ms/step - loss: 0.8947 - categorical_accuracy: 0.6062 - val_loss: 0.9676 - val_categorical_accuracy: 0.5819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ac3792db90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=384, validation_data=(x_test, y_test))\n",
    "# model.fit(x_train, y_train, epochs=25, batch_size=268, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 - 3s - loss: 0.9676 - categorical_accuracy: 0.5819 - 3s/epoch - 11ms/step\n",
      "319/319 [==============================] - 4s 12ms/step\n",
      "tf.Tensor(\n",
      "[[1755  483  323   37]\n",
      " [ 409 1908  210   37]\n",
      " [1290  518  644   82]\n",
      " [ 298  195  381 1626]], shape=(4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'softmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], Activation) \u001b[38;5;129;01mand\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m==\u001b[39m \u001b[43msoftmax\u001b[49m:\n\u001b[0;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(model\u001b[38;5;241m.\u001b[39minput, model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39moutput, name\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'softmax' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('project.h5')\n",
    "if isinstance(model.layers[-1], Activation) and model.layers[-1].activation == softmax:\n",
    "    model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)\n",
    "else:\n",
    "    print('Error: last layer is not SoftMax Activation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qualia_codegen_coreNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading qualia_codegen_core-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\elias\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from qualia_codegen_core) (1.24.2)\n",
      "Collecting jinja2 (from qualia_codegen_core)\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\elias\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from qualia_codegen_core) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\elias\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->qualia_codegen_core) (2.1.3)\n",
      "Downloading qualia_codegen_core-2.2.0-py3-none-any.whl (4.5 MB)\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.5 MB 1.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.3/4.5 MB 4.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.6/4.5 MB 5.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.9/4.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.2/4.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.5/4.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.8/4.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.1/4.5 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.4/4.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.7/4.5 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.1/4.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.4/4.5 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.8/4.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.9/4.5 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.2/4.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.5/4.5 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.5/4.5 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.2/133.2 kB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: jinja2, qualia_codegen_core\n",
      "Successfully installed jinja2-3.1.3 qualia_codegen_core-2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Cannot find PyTorch, PyTorch framework will be unavailable\n"
     ]
    }
   ],
   "source": [
    "%pip install qualia_codegen_core\n",
    "import qualia_codegen_core\n",
    "from qualia_codegen_core.graph.KerasModelGraph import KerasModelGraph\n",
    "from qualia_codegen_core.graph.Quantization import Quantization\n",
    "from qualia_codegen_core.graph.RoundMode import RoundMode\n",
    "\n",
    "from importlib.resources import files\n",
    "main_path = str((files('qualia_codegen_core.examples')/'Linux'/'main.cpp').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                                           | Layer                                            | Outputs                                          | Input shape                                      | Output shape                                    \n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                                 | input_1                                          | conv1d                                           | (1, 16000, 1)                                    | ((1, 16000, 1),)                                \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "input_1                                          | conv1d                                           | max_pooling1d                                    | (1, 16000, 1)                                    | ((1, 15998, 4),)                                \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d                                           | max_pooling1d                                    | conv1d_1                                         | (1, 15998, 4)                                    | ((1, 1999, 4),)                                 \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d                                    | conv1d_1                                         | max_pooling1d_1                                  | (1, 1999, 4)                                     | ((1, 1997, 4),)                                 \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_1                                         | max_pooling1d_1                                  | flatten                                          | (1, 1997, 4)                                     | ((1, 998, 4),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_1                                  | flatten                                          | dense                                            | (1, 998, 4)                                      | ((1, 3992),)                                    \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "flatten                                          | dense                                            | activation                                       | (1, 3992)                                        | ((1, 4),)                                       \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "dense                                            | activation                                       |                                                  | (1, 4)                                           | ((1, 4),)                                       \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelgraph = KerasModelGraph(model).convert()\n",
    "print(modelgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graphviz not available\n",
      "Activation function TActivation.SOFTMAX not supported\n",
      "ModelGraph validation failed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m float_res \u001b[38;5;241m=\u001b[39m qualia_codegen_core\u001b[38;5;241m.\u001b[39mConverter(output_path\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_output_floating\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mconvert_model(float_modelgraph)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_model_floating.h\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfloat_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not None"
     ]
    }
   ],
   "source": [
    "float_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for float32\n",
    "for node in float_modelgraph.nodes:\n",
    "    # No scale factor if not fixed-point quantization on integers\n",
    "    node.q = Quantization(\n",
    "            number_type=float,\n",
    "            width=32,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=0,\n",
    "            output_scale_factor=0,\n",
    "            weights_round_mode=RoundMode.NONE,\n",
    "            output_round_mode=RoundMode.NONE,\n",
    "            )\n",
    "\n",
    "float_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_floating')).convert_model(float_modelgraph)\n",
    "\n",
    "with open('gsc_model_floating.h', 'w') as f:\n",
    "    f.write(float_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cc1plus.exe: fatal error: gsc_output_fixed/model.c: No such file or directory\n",
      "compilation terminated.\n",
      "<command-line>: fatal error: gsc_output_fixed/include/defines.h: No such file or directory\n",
      "compilation terminated.\n"
     ]
    }
   ],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_fixed -include gsc_output_fixed/include/defines.h -Igsc_output_fixed/include gsc_output_fixed/model.c {main_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
