{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project EdgeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, shutil\n",
    "\n",
    "listQuery = [\"Emberiza citrinella\", \"Alauda arvensis\", \"Emberiza cirlus\", \"Cuculus canorus\"] #, \"Tyto alba\", \"Falco tinnunculus\", \"Sylvia borin\", \"Muscicapa striata\", \"Tachybaptus ruficollis\", \"Delichon urbicum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://xeno-canto.org/api/2/recordings?query=\"\n",
    "\n",
    "def enregistrer_mp3(url_api, nom_fichier):\n",
    "    reponse = requests.get(url_api, stream=True)\n",
    "    \n",
    "    if reponse.status_code == 200:\n",
    "        with open(nom_fichier, 'wb') as fichier_audio:\n",
    "            reponse.raw.decode_content = True\n",
    "            shutil.copyfileobj(reponse.raw, fichier_audio)\n",
    "        print(\"Audio enregistré avec succès sous le nom :\", nom_fichier)\n",
    "    else:\n",
    "        print(\"Erreur lors de la récupération des données audio depuis l'API\")\n",
    "\n",
    "def getData(query):\n",
    "    url_api = url + query\n",
    "    response = requests.get(url_api)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        contenu = response.json()[\"recordings\"]\n",
    "        pathToDir = \"./data/\" + query\n",
    "\n",
    "        if not os.path.exists(pathToDir):\n",
    "            os.mkdir(pathToDir)\n",
    "\n",
    "            for _, element in zip(range(250), contenu):\n",
    "                elementUrl = element[\"file\"]\n",
    "                elementFileName = element[\"file-name\"]\n",
    "                storeFile = pathToDir + \"/\" + elementFileName\n",
    "                \n",
    "                if not os.path.exists(storeFile):\n",
    "                    try:\n",
    "                        enregistrer_mp3(elementUrl, storeFile)\n",
    "                    except: # Pour les problèmes de noms de fichiers\n",
    "                        pass\n",
    "\n",
    "for query in listQuery:\n",
    "    getData(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import copy\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, MaxPool1D, Flatten, Dense, AvgPool1D, Activation\n",
    "from keras.utils import get_file\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "dataset_dir = Path('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all sound in X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "def slice_audio_with_trim(file_path, index, duration=1):\n",
    "    audio_data, sampling_rate = librosa.load(file_path, sr=None)\n",
    "    non_silent_audio, _ = librosa.effects.trim(audio_data)\n",
    "    num_slices = int(len(non_silent_audio) / sampling_rate / duration)\n",
    "\n",
    "    # Diviser l'audio en fonction de duration\n",
    "    for i in range(num_slices):\n",
    "        start = i * sampling_rate * duration\n",
    "        end = start + sampling_rate * duration\n",
    "        slice_data = non_silent_audio[start:end]\n",
    "\n",
    "        data = slice_data.astype(np.float32)\n",
    "        data.resize((16000, 1))\n",
    "\n",
    "        x.append(data)\n",
    "        y.append(index)\n",
    "\n",
    "def getAllDataClasses(directory, index):\n",
    "    for recording in dataset_dir.glob(f'{directory}/*'):\n",
    "        slice_audio_with_trim(str(recording) ,index)\n",
    "\n",
    "def loadAllData():\n",
    "    for i in range(len(listQuery)):\n",
    "        getAllDataClasses(listQuery[i], i)\n",
    "\n",
    "loadAllData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[   0 1121 2242 3363]\n",
      "[1121 1121 1121 1121]\n"
     ]
    }
   ],
   "source": [
    "u, indexes, counts = np.unique(y, return_index=True, return_counts=True)\n",
    "min = np.min(counts)\n",
    "nbrClasses = len(u)\n",
    "\n",
    "indices = np.random.permutation(min)\n",
    "\n",
    "newX = []\n",
    "newY = []\n",
    "\n",
    "for i in range(nbrClasses):\n",
    "    sousSetX = []\n",
    "    sousSetY = []\n",
    "    \n",
    "    if i == nbrClasses - 1:\n",
    "        sousSetX = x[indexes[i]:]\n",
    "        sousSetY = y[indexes[i]:]\n",
    "    else:\n",
    "        sousSetX = x[indexes[i] : indexes[i + 1]]\n",
    "        sousSetY = y[indexes[i] : indexes[i + 1]]\n",
    "    \n",
    "    x_selectionne = [sousSetX[j] for j in indices]\n",
    "    y_selectionne = [sousSetY[j] for j in indices]\n",
    "\n",
    "    for x_s, y_s in zip(x_selectionne, y_selectionne):\n",
    "        newX.append(x_s)\n",
    "        newY.append(y_s)\n",
    "\n",
    "u, indexes, counts = np.unique(newY, return_index=True, return_counts=True)\n",
    "print(u)\n",
    "print(indexes)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(newX, newY, test_size=0.2)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "y_test = to_categorical(np.array(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3587, 16000, 1) (897, 16000, 1)\n",
      "(3587, 4) (897, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 15998, 4)          16        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1999, 4)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1997, 4)           52        \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 998, 4)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3992)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 15972     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,040\n",
      "Trainable params: 16,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=8))\n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4))\n",
    "model.add(Activation('softmax')) # SoftMax activation needs to be separate from Dense to remove it later on\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-4)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 1.3858 - categorical_accuracy: 0.2715 - val_loss: 1.3834 - val_categorical_accuracy: 0.3512\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 1.3709 - categorical_accuracy: 0.3490 - val_loss: 1.3441 - val_categorical_accuracy: 0.2598\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 1.3088 - categorical_accuracy: 0.2715 - val_loss: 1.2445 - val_categorical_accuracy: 0.3790\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 1.2141 - categorical_accuracy: 0.3546 - val_loss: 1.1680 - val_categorical_accuracy: 0.4615\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 1.1572 - categorical_accuracy: 0.4904 - val_loss: 1.1366 - val_categorical_accuracy: 0.4783\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 1.1367 - categorical_accuracy: 0.4976 - val_loss: 1.1265 - val_categorical_accuracy: 0.4950\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 1.1274 - categorical_accuracy: 0.5244 - val_loss: 1.1181 - val_categorical_accuracy: 0.5050\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 1.1187 - categorical_accuracy: 0.5347 - val_loss: 1.1102 - val_categorical_accuracy: 0.5006\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 2s 242ms/step - loss: 1.1114 - categorical_accuracy: 0.5431 - val_loss: 1.1032 - val_categorical_accuracy: 0.5351\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 2s 241ms/step - loss: 1.1048 - categorical_accuracy: 0.5701 - val_loss: 1.0977 - val_categorical_accuracy: 0.5284\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 1.0989 - categorical_accuracy: 0.5751 - val_loss: 1.0928 - val_categorical_accuracy: 0.5474\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 2s 244ms/step - loss: 1.0938 - categorical_accuracy: 0.5634 - val_loss: 1.0880 - val_categorical_accuracy: 0.5440\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 1.0888 - categorical_accuracy: 0.5807 - val_loss: 1.0832 - val_categorical_accuracy: 0.5474\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 1.0835 - categorical_accuracy: 0.5684 - val_loss: 1.0796 - val_categorical_accuracy: 0.5162\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 1.0786 - categorical_accuracy: 0.5707 - val_loss: 1.0749 - val_categorical_accuracy: 0.5229\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 2s 244ms/step - loss: 1.0736 - categorical_accuracy: 0.5578 - val_loss: 1.0701 - val_categorical_accuracy: 0.4972\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 2s 244ms/step - loss: 1.0691 - categorical_accuracy: 0.5470 - val_loss: 1.0654 - val_categorical_accuracy: 0.4716\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 1.0638 - categorical_accuracy: 0.5562 - val_loss: 1.0609 - val_categorical_accuracy: 0.5039\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 2s 244ms/step - loss: 1.0583 - categorical_accuracy: 0.5180 - val_loss: 1.0555 - val_categorical_accuracy: 0.5139\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 1.0521 - categorical_accuracy: 0.5275 - val_loss: 1.0506 - val_categorical_accuracy: 0.4337\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 1.0449 - categorical_accuracy: 0.4667 - val_loss: 1.0419 - val_categorical_accuracy: 0.4582\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 2s 241ms/step - loss: 1.0340 - categorical_accuracy: 0.4491 - val_loss: 1.0237 - val_categorical_accuracy: 0.4738\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 2s 242ms/step - loss: 1.0108 - categorical_accuracy: 0.4452 - val_loss: 0.9884 - val_categorical_accuracy: 0.5017\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 0.9604 - categorical_accuracy: 0.5311 - val_loss: 0.9035 - val_categorical_accuracy: 0.5987\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.8901 - categorical_accuracy: 0.5930 - val_loss: 0.8702 - val_categorical_accuracy: 0.6243\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.8598 - categorical_accuracy: 0.6117 - val_loss: 0.8519 - val_categorical_accuracy: 0.6310\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 0.8484 - categorical_accuracy: 0.6295 - val_loss: 0.8346 - val_categorical_accuracy: 0.6176\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 3s 254ms/step - loss: 0.8501 - categorical_accuracy: 0.5969 - val_loss: 0.8250 - val_categorical_accuracy: 0.6143\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.8405 - categorical_accuracy: 0.6401 - val_loss: 0.8204 - val_categorical_accuracy: 0.6355\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.8250 - categorical_accuracy: 0.6496 - val_loss: 0.8172 - val_categorical_accuracy: 0.6243\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 2s 242ms/step - loss: 0.8176 - categorical_accuracy: 0.6228 - val_loss: 0.8168 - val_categorical_accuracy: 0.6299\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 3s 254ms/step - loss: 0.8212 - categorical_accuracy: 0.6345 - val_loss: 0.8133 - val_categorical_accuracy: 0.6087\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 2s 242ms/step - loss: 0.8189 - categorical_accuracy: 0.6395 - val_loss: 0.8010 - val_categorical_accuracy: 0.6176\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 2s 242ms/step - loss: 0.8057 - categorical_accuracy: 0.6418 - val_loss: 0.7834 - val_categorical_accuracy: 0.6444\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.7870 - categorical_accuracy: 0.6526 - val_loss: 0.7760 - val_categorical_accuracy: 0.6355\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 2s 241ms/step - loss: 0.7793 - categorical_accuracy: 0.6663 - val_loss: 0.7769 - val_categorical_accuracy: 0.6533\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.7755 - categorical_accuracy: 0.6498 - val_loss: 0.7666 - val_categorical_accuracy: 0.6332\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.7709 - categorical_accuracy: 0.6716 - val_loss: 0.7574 - val_categorical_accuracy: 0.6555\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 2s 245ms/step - loss: 0.7646 - categorical_accuracy: 0.6543 - val_loss: 0.7555 - val_categorical_accuracy: 0.6421\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.7643 - categorical_accuracy: 0.6788 - val_loss: 0.7593 - val_categorical_accuracy: 0.6499\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 3s 256ms/step - loss: 0.7649 - categorical_accuracy: 0.6596 - val_loss: 0.7536 - val_categorical_accuracy: 0.6466\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 3s 252ms/step - loss: 0.7623 - categorical_accuracy: 0.6816 - val_loss: 0.7543 - val_categorical_accuracy: 0.6366\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 2s 244ms/step - loss: 0.7556 - categorical_accuracy: 0.6688 - val_loss: 0.7583 - val_categorical_accuracy: 0.6566\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 3s 254ms/step - loss: 0.7526 - categorical_accuracy: 0.6677 - val_loss: 0.7460 - val_categorical_accuracy: 0.6656\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 2s 244ms/step - loss: 0.7565 - categorical_accuracy: 0.6774 - val_loss: 0.7478 - val_categorical_accuracy: 0.6388\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.7432 - categorical_accuracy: 0.6752 - val_loss: 0.7473 - val_categorical_accuracy: 0.6711\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 3s 252ms/step - loss: 0.7413 - categorical_accuracy: 0.6800 - val_loss: 0.7453 - val_categorical_accuracy: 0.6622\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 3s 253ms/step - loss: 0.7413 - categorical_accuracy: 0.6908 - val_loss: 0.7499 - val_categorical_accuracy: 0.6589\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 3s 254ms/step - loss: 0.7345 - categorical_accuracy: 0.6853 - val_loss: 0.7414 - val_categorical_accuracy: 0.6678\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 2s 251ms/step - loss: 0.7330 - categorical_accuracy: 0.6911 - val_loss: 0.7419 - val_categorical_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7b8b70a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=384, validation_data=(x_test, y_test))\n",
    "# model.fit(x_train, y_train, epochs=25, batch_size=268, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 0s - loss: 0.7419 - categorical_accuracy: 0.6667 - 283ms/epoch - 10ms/step\n",
      "29/29 [==============================] - 0s 9ms/step\n",
      "tf.Tensor(\n",
      "[[175  19  20   9]\n",
      " [ 22 177   5   0]\n",
      " [157  32  38  14]\n",
      " [ 17   0   4 208]], shape=(4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('project.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find PyTorch, PyTorch framework will be unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qualia_codegen_core in c:\\users\\bobca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bobca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from qualia_codegen_core) (3.1.3)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\bobca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from qualia_codegen_core) (4.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\bobca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from qualia_codegen_core) (1.24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bobca\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->qualia_codegen_core) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qualia_codegen_core\n",
    "import qualia_codegen_core\n",
    "from qualia_codegen_core.graph.KerasModelGraph import KerasModelGraph\n",
    "from qualia_codegen_core.graph.Quantization import Quantization\n",
    "from qualia_codegen_core.graph.RoundMode import RoundMode\n",
    "\n",
    "from importlib.resources import files\n",
    "main_path = str((files('qualia_codegen_core.examples')/'Linux'/'main.cpp').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                                           | Layer                                            | Outputs                                          | Input shape                                      | Output shape                                    \n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                                 | input_1                                          | conv1d                                           | (1, 16000, 1)                                    | ((1, 16000, 1),)                                \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "input_1                                          | conv1d                                           | max_pooling1d                                    | (1, 16000, 1)                                    | ((1, 15998, 4),)                                \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d                                           | max_pooling1d                                    | conv1d_1                                         | (1, 15998, 4)                                    | ((1, 1999, 4),)                                 \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d                                    | conv1d_1                                         | max_pooling1d_1                                  | (1, 1999, 4)                                     | ((1, 1997, 4),)                                 \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_1                                         | max_pooling1d_1                                  | flatten                                          | (1, 1997, 4)                                     | ((1, 998, 4),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_1                                  | flatten                                          | dense                                            | (1, 998, 4)                                      | ((1, 3992),)                                    \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "flatten                                          | dense                                            | activation                                       | (1, 3992)                                        | ((1, 4),)                                       \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "dense                                            | activation                                       |                                                  | (1, 4)                                           | ((1, 4),)                                       \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelgraph = KerasModelGraph(model).convert()\n",
    "print(modelgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\activation\n",
      "......vars\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\max_pooling1d\n",
      "......vars\n",
      "...layers\\max_pooling1d_1\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-21 23:51:27         3128\n",
      "metadata.json                                  2024-04-21 23:51:27           64\n",
      "variables.h5                                   2024-04-21 23:51:27       223432\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-21 23:51:26         3128\n",
      "metadata.json                                  2024-04-21 23:51:26           64\n",
      "variables.h5                                   2024-04-21 23:51:26       223432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graphviz not available\n",
      "Activation function TActivation.SOFTMAX not supported\n",
      "ModelGraph validation failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\activation\n",
      "......vars\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\max_pooling1d\n",
      "......vars\n",
      "...layers\\max_pooling1d_1\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_model_floating.h\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(float_res)\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfloat_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not None"
     ]
    }
   ],
   "source": [
    "float_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for float32\n",
    "for node in float_modelgraph.nodes:\n",
    "    # No scale factor if not fixed-point quantization on integers\n",
    "    node.q = Quantization(\n",
    "            number_type=float,\n",
    "            width=32,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=0,\n",
    "            output_scale_factor=0,\n",
    "            weights_round_mode=RoundMode.NONE,\n",
    "            output_round_mode=RoundMode.NONE,\n",
    "            )\n",
    "\n",
    "float_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_floating')).convert_model(float_modelgraph)\n",
    "\n",
    "with open('gsc_model_floating.h', 'w') as f:\n",
    "    f.write(float_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cc1plus.exe: fatal error: gsc_output_fixed/model.c: No such file or directory\n",
      "compilation terminated.\n",
      "<command-line>: fatal error: gsc_output_fixed/include/defines.h: No such file or directory\n",
      "compilation terminated.\n"
     ]
    }
   ],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_fixed -include gsc_output_fixed/include/defines.h -Igsc_output_fixed/include gsc_output_fixed/model.c {main_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
